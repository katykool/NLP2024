{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Автобрея, ДЗ1. Парсер. Катя Шерстнева\n",
        "Анализ тональности отзывов смотри во второй части"
      ],
      "metadata": {
        "id": "v040GpWWfz95"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f7vsLdbtfq-M"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import regex as re\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Парсим отзывы на книги"
      ],
      "metadata": {
        "id": "Ys9skr5FgIXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала пройдемся по главной страничке отзывов с книгами и соберем ссылки на странички с отзывами для каждой книги"
      ],
      "metadata": {
        "id": "GHuOQelWgNyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(main_link=str, n_pages=int):\n",
        "  list_of_urls = []\n",
        "\n",
        "  for page in tqdm(range(1, n_pages)):\n",
        "    response = requests.get(f\"{main_link}?page={page}\")\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    post = soup.find_all('div', {'class': 'item_links'})\n",
        "\n",
        "    for p in post:\n",
        "\n",
        "      url = re.search('<a href=\"(.*?)\" title', str(p))\n",
        "      list_of_urls.append('https://vseotzyvy.ru/'+ url.group(1))\n",
        "\n",
        "  points = [] # оценки\n",
        "  rew = [] # текст отзыва\n",
        "\n",
        "  for url in tqdm(list_of_urls):\n",
        "\n",
        "      r_pos = requests.get(url)\n",
        "\n",
        "      soup = BeautifulSoup(r_pos.text, 'html.parser')\n",
        "\n",
        "      stars = soup.find_all('div', {'class': 'rev_rate_box'})\n",
        "      for el in stars:\n",
        "        st = re.search('<span class=\"bold\" itemprop=\"ratingValue\">(\\d)</span>', str(el)).group(1)\n",
        "        points.append(st)\n",
        "\n",
        "      texts = soup.find_all('span', {'itemprop':'reviewBody'})\n",
        "      for t in texts:\n",
        "        clean_text = re.search('<span itemprop=\"reviewBody\">(.*?)</span>', str(t))\n",
        "        if clean_text is None:\n",
        "          pass\n",
        "        else:\n",
        "          clean_text = clean_text.group(1)\n",
        "        rew.append(clean_text)\n",
        "\n",
        "  return points, rew"
      ],
      "metadata": {
        "id": "mKIriD_4hf2L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "journals = parse('https://vseotzyvy.ru/category/167/gazetyi-zhurnalyi', 11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cz1Z8n9KiDGZ",
        "outputId": "0dcc740a-4a43-4a78-a4f1-94b2c1261ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:06<00:00,  1.56it/s]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(journals[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffl66zBfj9u1",
        "outputId": "f8a28ba6-ccb4-49bc-9e3f-de35278ba41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'4': 115, '5': 436, '3': 52, '1': 29, '2': 17})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books = parse('https://vseotzyvy.ru/category/166/knigi', 67)"
      ],
      "metadata": {
        "id": "9WE8AKx5i9_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parced_to_df(points=list, rew=list):\n",
        "\n",
        "  df = pd.DataFrame(columns=['text', 'label'])\n",
        "\n",
        "  c=0\n",
        "\n",
        "  for p, r in zip(points, rew):\n",
        "    if r is not None:\n",
        "      if int(p)==5:\n",
        "        df.at [c, 'text'] = r\n",
        "        df.at [c, 'label'] = 1\n",
        "\n",
        "      if int(p)<3:\n",
        "        df.at [c, 'text'] = r\n",
        "        df.at [c, 'label'] = 0\n",
        "    c+=1\n",
        "  return df"
      ],
      "metadata": {
        "id": "Cy3NqwO_iVh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_b = parced_to_df(books)\n",
        "df_j = parced_to_df(journals[0], journals[1])\n",
        "\n",
        "df_0 = df_b[df_b['label'] == 0].sample(n=70, random_state=42)\n",
        "df_1 = df_b[df_b['label'] == 1].sample(n=70, random_state=42)\n",
        "\n",
        "df_2 = df_j[df_j['label'] == 0].sample(n=33, random_state=42)\n",
        "df_3 = df_j[df_j['label'] == 1].sample(n=33, random_state=42)\n",
        "\n",
        "# Объединяем выборки\n",
        "df_final = pd.concat([df_0, df_1, df_2, df_3])\n",
        "df_final = df_final.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "n2x9n1SFjTdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.to_csv('reviews.csv')"
      ],
      "metadata": {
        "id": "N8Rfw_rBlUZg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}